{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "754c39dc045a46a48a6aa4438f3249a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FileUploadModel",
          "model_module_version": "1.5.0",
          "state": {
            "_counter": 0,
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FileUploadModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FileUploadView",
            "accept": ".jpg,.jpeg,.png",
            "button_style": "",
            "data": [],
            "description": "Upload",
            "description_tooltip": null,
            "disabled": false,
            "error": "",
            "icon": "upload",
            "layout": "IPY_MODEL_eb26addf03cf47f0b82ec3452b8aca28",
            "metadata": [],
            "multiple": false,
            "style": "IPY_MODEL_c3f38945fd98402e84a2c6bc68cd69e8"
          }
        },
        "eb26addf03cf47f0b82ec3452b8aca28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3f38945fd98402e84a2c6bc68cd69e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWHHl5OeYrU7",
        "outputId": "174fa87e-7b39-4f48-95a3-139d153a99c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.14)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# configuring the path of Kaggle.json file\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "loERMQj6Yvib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing dataset\n",
        "!kaggle datasets download -d vuppalaadithyasairam/bone-fracture-detection-using-xrays\n",
        "!kaggle datasets download -d bebofekry/bone-fracture-atlas-ds-compressed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZrX4GePaD8I",
        "outputId": "51536c4f-ebac-4d6a-d099-e6e7f49ffaa0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/vuppalaadithyasairam/bone-fracture-detection-using-xrays\n",
            "License(s): unknown\n",
            "Downloading bone-fracture-detection-using-xrays.zip to /content\n",
            " 89% 153M/172M [00:02<00:00, 64.4MB/s]\n",
            "100% 172M/172M [00:02<00:00, 70.5MB/s]\n",
            "Dataset URL: https://www.kaggle.com/datasets/bebofekry/bone-fracture-atlas-ds-compressed\n",
            "License(s): unknown\n",
            "Downloading bone-fracture-atlas-ds-compressed.zip to /content\n",
            " 95% 118M/125M [00:01<00:00, 81.7MB/s] \n",
            "100% 125M/125M [00:02<00:00, 65.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#extract the file\n",
        "from zipfile import ZipFile\n",
        "\n",
        "dataset1 ='/content/bone-fracture-atlas-ds-compressed.zip'\n",
        "\n",
        "dataset2 = '/content/bone-fracture-detection-using-xrays.zip'\n",
        "\n",
        "with ZipFile(dataset1, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('The dataset is extracted')\n",
        "\n",
        "with ZipFile(dataset2, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('The dataset is extracted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8y4ecSzAaGjW",
        "outputId": "52014ded-8041-4714-dafa-b6979d8fcfe2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset is extracted\n",
            "The dataset is extracted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "0MVfDSvgaYQ3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fractured_files1=os.listdir('/content/archive (6)/train/fractured')\n",
        "fractured_files2=os.listdir('/content/FracAtlas/FracAtlas/images/Train/Fractured')\n",
        "fractured_files3=os.listdir('/content/FracAtlas/FracAtlas/images/Test/Fractured')\n",
        "fractured_files=fractured_files1+fractured_files2+fractured_files3\n",
        "print(fractured_files[0:5])\n",
        "print(fractured_files[-5:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQHP_820eB-i",
        "outputId": "a8e2bb45-6aaa-44cf-b569-065e77c7509b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['84-rotated3-rotated3-rotated3.jpg', '62.jpg', '54-rotated3-rotated3.jpg', '51-rotated3-rotated1.jpg', '91-rotated3-rotated1-rotated2.jpg']\n",
            "['IMG0001366.jpg', 'IMG0001200.jpg', 'IMG0000443.jpg', 'IMG0001350.jpg', 'IMG0000805.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "not_fractured_files1=os.listdir('/content/archive (6)/train/not fractured')\n",
        "not_fractured_files2=os.listdir('/content/FracAtlas/FracAtlas/images/Train/Non_fractured')\n",
        "not_fractured_files3=os.listdir('/content/FracAtlas/FracAtlas/images/Test/Non_fractured')\n",
        "not_fractured_files=not_fractured_files1+not_fractured_files2+not_fractured_files3\n",
        "print(fractured_files[0:5])\n",
        "print(fractured_files[-5:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ62t6iAeKFQ",
        "outputId": "f3f8a715-b81a-4c7f-948b-6a788beeb54d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['84-rotated3-rotated3-rotated3.jpg', '62.jpg', '54-rotated3-rotated3.jpg', '51-rotated3-rotated1.jpg', '91-rotated3-rotated1-rotated2.jpg']\n",
            "['IMG0001366.jpg', 'IMG0001200.jpg', 'IMG0000443.jpg', 'IMG0001350.jpg', 'IMG0000805.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of with fractured images:', len(fractured_files))\n",
        "print('Number of not fractured images:', len(not_fractured_files))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAXgkPNQfWZ2",
        "outputId": "bc98ce63-65ab-43a5-d846-d0d1f12f3b6a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of with fractured images: 5292\n",
            "Number of not fractured images: 5371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Labels\n",
        "\n",
        "0 -> Not Fractured\n",
        "1 -> Fractured"
      ],
      "metadata": {
        "id": "tbgq5M3ifgfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the labels\n",
        "\n",
        "fractured_labels = [1]*5292\n",
        "\n",
        "not_fractured_labels = [0]*5371"
      ],
      "metadata": {
        "id": "bsKz17ZffgEk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating total labels\n",
        "\n",
        "print(len(fractured_labels))\n",
        "print(len(not_fractured_labels))\n",
        "\n",
        "labels = fractured_labels+not_fractured_labels\n",
        "\n",
        "print(len(labels))\n",
        "print(labels[0:5])\n",
        "print(labels[-5:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtwWuQwBfZ9t",
        "outputId": "325e6e5a-6435-4830-9d54-a8f394ef0af9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5292\n",
            "5371\n",
            "10663\n",
            "[1, 1, 1, 1, 1]\n",
            "[0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image Processing\n",
        "\n",
        "Resizing Images\n",
        "\n",
        "Converting images into numpy arrays"
      ],
      "metadata": {
        "id": "nYQEm9zuf3As"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=[]\n",
        "\n",
        "fractured_path1='/content/archive (6)/train/fractured/'\n",
        "fractured_path2='/content/FracAtlas/FracAtlas/images/Train/Fractured/'\n",
        "fractured_path3='/content/FracAtlas/FracAtlas/images/Test/Fractured/'\n",
        "\n",
        "for img_file in fractured_files1:\n",
        "  image = Image.open(fractured_path1 + img_file)\n",
        "  image = image.resize((128,128))\n",
        "  image = image.convert('RGB')\n",
        "  image = np.array(image)\n",
        "  data.append(image)\n",
        "\n",
        "for img_file in fractured_files2:\n",
        "  image = Image.open(fractured_path2 + img_file)\n",
        "  image = image.resize((128,128))\n",
        "  image = image.convert('RGB')\n",
        "  image = np.array(image)\n",
        "  data.append(image)\n",
        "\n",
        "for img_file in fractured_files3:\n",
        "  image = Image.open(fractured_path3 + img_file)\n",
        "  image = image.resize((128,128))\n",
        "  image = image.convert('RGB')\n",
        "  image = np.array(image)\n",
        "  data.append(image)\n",
        "\n",
        "\n",
        "not_fractured_path1='/content/archive (6)/train/not fractured/'\n",
        "not_fractured_path2='/content/FracAtlas/FracAtlas/images/Train/Non_fractured/'\n",
        "not_fractured_path3='/content/FracAtlas/FracAtlas/images/Test/Non_fractured/'\n",
        "\n",
        "for img_file in not_fractured_files1:\n",
        "  image = Image.open(not_fractured_path1 + img_file)\n",
        "  image = image.resize((128,128))\n",
        "  image = image.convert('RGB')\n",
        "  image = np.array(image)\n",
        "  data.append(image)\n",
        "\n",
        "for img_file in not_fractured_files2:\n",
        "  image = Image.open(not_fractured_path2 + img_file)\n",
        "  image = image.resize((128,128))\n",
        "  image = image.convert('RGB')\n",
        "  image = np.array(image)\n",
        "  data.append(image)\n",
        "\n",
        "for img_file in not_fractured_files3:\n",
        "  image = Image.open(not_fractured_path3 + img_file)\n",
        "  image = image.resize((128,128))\n",
        "  image = image.convert('RGB')\n",
        "  image = np.array(image)\n",
        "  data.append(image)"
      ],
      "metadata": {
        "id": "1pjHHFgcfv8e"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting image list and label list to numpy arrays\n",
        "\n",
        "X = np.array(data)\n",
        "Y = np.array(labels)"
      ],
      "metadata": {
        "id": "teW7D5aihPCs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdFur5gizKYT"
      },
      "source": [
        "**Train Test Split**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)"
      ],
      "metadata": {
        "id": "WbYjRaQ2hbN6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape, X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZuA1ik3hgb0",
        "outputId": "60ded32e-056c-4987-9d6c-db99cd0d3778"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10663, 128, 128, 3) (8530, 128, 128, 3) (2133, 128, 128, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scaling the data\n",
        "\n",
        "X_train_scaled = X_train/255\n",
        "\n",
        "X_test_scaled = X_test/255"
      ],
      "metadata": {
        "id": "wxRPsoRohiAC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolution Neural Network - CNN"
      ],
      "metadata": {
        "id": "udT1ElEqhpbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "73Tl-iukhl90"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_of_classes = 2\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(128,128,3)))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "model.add(keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(keras.layers.Flatten())\n",
        "\n",
        "model.add(keras.layers.Dense(128, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "model.add(keras.layers.Dense(64, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(keras.layers.Dense(num_of_classes, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "xCSbzUHOhtjz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the neural network\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "id": "qw3BwiGnhyoc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training the neural network\n",
        "history = model.fit(X_train_scaled, Y_train, validation_split=0.1, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-Y6GOfCh2G4",
        "outputId": "719bf45a-901a-4c67-d241-c490962d7650"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "240/240 [==============================] - 200s 821ms/step - loss: 0.6512 - acc: 0.6133 - val_loss: 0.5338 - val_acc: 0.7222\n",
            "Epoch 2/5\n",
            "240/240 [==============================] - 200s 835ms/step - loss: 0.4734 - acc: 0.7705 - val_loss: 0.3540 - val_acc: 0.8499\n",
            "Epoch 3/5\n",
            "240/240 [==============================] - 194s 810ms/step - loss: 0.3110 - acc: 0.8613 - val_loss: 0.2972 - val_acc: 0.8710\n",
            "Epoch 4/5\n",
            "240/240 [==============================] - 207s 864ms/step - loss: 0.2042 - acc: 0.9139 - val_loss: 0.2197 - val_acc: 0.9285\n",
            "Epoch 5/5\n",
            "240/240 [==============================] - 198s 825ms/step - loss: 0.1525 - acc: 0.9394 - val_loss: 0.2158 - val_acc: 0.9273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "# Predicting on test data\n",
        "y_pred_prob = model.predict(X_test_scaled)\n",
        "\n",
        "# Converting probabilities to class labels\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "# Calculating precision, recall, and f1-score\n",
        "precision = precision_score(Y_test, y_pred)\n",
        "recall = recall_score(Y_test, y_pred)\n",
        "f1 = f1_score(Y_test, y_pred)\n",
        "\n",
        "# Evaluation of Accuracy\n",
        "loss, accuracy = model.evaluate(X_test_scaled, Y_test)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print('Test Accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiVHQz3EojxD",
        "outputId": "0f17c32c-f2db-4e62-b154-b203e0e02900"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67/67 [==============================] - 15s 224ms/step\n",
            "67/67 [==============================] - 15s 228ms/step - loss: 0.1893 - acc: 0.9292\n",
            "Precision: 0.9552238805970149\n",
            "Recall: 0.900562851782364\n",
            "F1-score: 0.927088363109609\n",
            "Test Accuracy: 0.9292076826095581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save(\"my_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMgUjaDHbwoY",
        "outputId": "b14e3a5d-064f-4e44-ab0b-831bd8f60412"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.keras.models import load_model\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "# Load the model\n",
        "loaded_model = load_model(\"my_model.h5\")\n",
        "\n",
        "def predict_image(image_path):\n",
        "    input_image = cv2.imread(image_path)\n",
        "    input_image_resized = cv2.resize(input_image, (128,128))\n",
        "    input_image_scaled = input_image_resized / 255\n",
        "    input_image_reshaped = np.reshape(input_image_scaled, [1,128,128,3])\n",
        "    input_prediction = loaded_model.predict(input_image_reshaped)\n",
        "    input_pred_label = np.argmax(input_prediction)\n",
        "    if input_pred_label == 1:\n",
        "        print('The bone is fractured')\n",
        "    else:\n",
        "        print('The bone is not fractured')\n",
        "\n",
        "# Create a file upload widget\n",
        "file_upload = widgets.FileUpload(accept='.jpg,.jpeg,.png')\n",
        "\n",
        "# Define a function to handle file upload\n",
        "def on_file_upload(change):\n",
        "    if file_upload.value:\n",
        "        file_contents = file_upload.value[next(iter(file_upload.value))]\n",
        "        with open('uploaded_image.jpg', 'wb') as f:\n",
        "            f.write(file_contents['content'])\n",
        "        print('Image uploaded successfully!')\n",
        "        predict_image('uploaded_image.jpg')\n",
        "\n",
        "file_upload.observe(on_file_upload, names='_counter')\n",
        "\n",
        "display(file_upload)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "754c39dc045a46a48a6aa4438f3249a6",
            "eb26addf03cf47f0b82ec3452b8aca28",
            "c3f38945fd98402e84a2c6bc68cd69e8"
          ]
        },
        "id": "P3rilf4LeisP",
        "outputId": "bcc59a0e-6fe3-4f37-b922-640d3d0a7340"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FileUpload(value={}, accept='.jpg,.jpeg,.png', description='Upload')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "754c39dc045a46a48a6aa4438f3249a6"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}