# -*- coding: utf-8 -*-
"""Bone_Fracture_Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ce_Zg5QvH3FTaxAFfbOicn3LBsZItisT
"""

!pip install kaggle

# configuring the path of Kaggle.json file
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

#importing dataset
!kaggle datasets download -d vuppalaadithyasairam/bone-fracture-detection-using-xrays
!kaggle datasets download -d bebofekry/bone-fracture-atlas-ds-compressed

#extract the file
from zipfile import ZipFile

dataset1 ='/content/bone-fracture-atlas-ds-compressed.zip'

dataset2 = '/content/bone-fracture-detection-using-xrays.zip'

with ZipFile(dataset1, 'r') as zip:
  zip.extractall()
  print('The dataset is extracted')

with ZipFile(dataset2, 'r') as zip:
  zip.extractall()
  print('The dataset is extracted')

import os
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import cv2
from google.colab.patches import cv2_imshow
from PIL import Image
from sklearn.model_selection import train_test_split

fractured_files1=os.listdir('/content/archive (6)/train/fractured')
fractured_files2=os.listdir('/content/FracAtlas/FracAtlas/images/Train/Fractured')
fractured_files3=os.listdir('/content/FracAtlas/FracAtlas/images/Test/Fractured')
fractured_files=fractured_files1+fractured_files2+fractured_files3
print(fractured_files[0:5])
print(fractured_files[-5:])

not_fractured_files1=os.listdir('/content/archive (6)/train/not fractured')
not_fractured_files2=os.listdir('/content/FracAtlas/FracAtlas/images/Train/Non_fractured')
not_fractured_files3=os.listdir('/content/FracAtlas/FracAtlas/images/Test/Non_fractured')
not_fractured_files=not_fractured_files1+not_fractured_files2+not_fractured_files3
print(fractured_files[0:5])
print(fractured_files[-5:])

print('Number of with fractured images:', len(fractured_files))
print('Number of not fractured images:', len(not_fractured_files))

"""Creating Labels

0 -> Not Fractured
1 -> Fractured
"""

# create the labels

fractured_labels = [1]*5292

not_fractured_labels = [0]*5371

# calculating total labels

print(len(fractured_labels))
print(len(not_fractured_labels))

labels = fractured_labels+not_fractured_labels

print(len(labels))
print(labels[0:5])
print(labels[-5:])

"""Image Processing

Resizing Images

Converting images into numpy arrays
"""

data=[]

fractured_path1='/content/archive (6)/train/fractured/'
fractured_path2='/content/FracAtlas/FracAtlas/images/Train/Fractured/'
fractured_path3='/content/FracAtlas/FracAtlas/images/Test/Fractured/'

for img_file in fractured_files1:
  image = Image.open(fractured_path1 + img_file)
  image = image.resize((128,128))
  image = image.convert('RGB')
  image = np.array(image)
  data.append(image)

for img_file in fractured_files2:
  image = Image.open(fractured_path2 + img_file)
  image = image.resize((128,128))
  image = image.convert('RGB')
  image = np.array(image)
  data.append(image)

for img_file in fractured_files3:
  image = Image.open(fractured_path3 + img_file)
  image = image.resize((128,128))
  image = image.convert('RGB')
  image = np.array(image)
  data.append(image)


not_fractured_path1='/content/archive (6)/train/not fractured/'
not_fractured_path2='/content/FracAtlas/FracAtlas/images/Train/Non_fractured/'
not_fractured_path3='/content/FracAtlas/FracAtlas/images/Test/Non_fractured/'

for img_file in not_fractured_files1:
  image = Image.open(not_fractured_path1 + img_file)
  image = image.resize((128,128))
  image = image.convert('RGB')
  image = np.array(image)
  data.append(image)

for img_file in not_fractured_files2:
  image = Image.open(not_fractured_path2 + img_file)
  image = image.resize((128,128))
  image = image.convert('RGB')
  image = np.array(image)
  data.append(image)

for img_file in not_fractured_files3:
  image = Image.open(not_fractured_path3 + img_file)
  image = image.resize((128,128))
  image = image.convert('RGB')
  image = np.array(image)
  data.append(image)

# converting image list and label list to numpy arrays

X = np.array(data)
Y = np.array(labels)

"""**Train Test Split**"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)

print(X.shape, X_train.shape, X_test.shape)

# scaling the data

X_train_scaled = X_train/255

X_test_scaled = X_test/255

"""Convolution Neural Network - CNN"""

import tensorflow as tf
from tensorflow import keras

num_of_classes = 2

model = keras.Sequential()

model.add(keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(128,128,3)))
model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))


model.add(keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))
model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))

model.add(keras.layers.Flatten())

model.add(keras.layers.Dense(128, activation='relu'))
model.add(keras.layers.Dropout(0.5))

model.add(keras.layers.Dense(64, activation='relu'))
model.add(keras.layers.Dropout(0.5))


model.add(keras.layers.Dense(num_of_classes, activation='sigmoid'))

# compile the neural network
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['acc'])

# training the neural network
history = model.fit(X_train_scaled, Y_train, validation_split=0.1, epochs=5)

from sklearn.metrics import precision_score, recall_score, f1_score
# Predicting on test data
y_pred_prob = model.predict(X_test_scaled)

# Converting probabilities to class labels
y_pred = np.argmax(y_pred_prob, axis=1)

# Calculating precision, recall, and f1-score
precision = precision_score(Y_test, y_pred)
recall = recall_score(Y_test, y_pred)
f1 = f1_score(Y_test, y_pred)

# Evaluation of Accuracy
loss, accuracy = model.evaluate(X_test_scaled, Y_test)

print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)
print('Test Accuracy:', accuracy)

# Save the model
model.save("my_model.h5")

import cv2
import numpy as np
from google.colab.patches import cv2_imshow
from tensorflow.keras.models import load_model
import ipywidgets as widgets
from IPython.display import display


# Load the model
loaded_model = load_model("my_model.h5")

def predict_image(image_path):
    input_image = cv2.imread(image_path)
    input_image_resized = cv2.resize(input_image, (128,128))
    input_image_scaled = input_image_resized / 255
    input_image_reshaped = np.reshape(input_image_scaled, [1,128,128,3])
    input_prediction = loaded_model.predict(input_image_reshaped)
    input_pred_label = np.argmax(input_prediction)
    if input_pred_label == 1:
        print('The bone is fractured')
    else:
        print('The bone is not fractured')

# Create a file upload widget
file_upload = widgets.FileUpload(accept='.jpg,.jpeg,.png')

# Define a function to handle file upload
def on_file_upload(change):
    if file_upload.value:
        file_contents = file_upload.value[next(iter(file_upload.value))]
        with open('uploaded_image.jpg', 'wb') as f:
            f.write(file_contents['content'])
        print('Image uploaded successfully!')
        predict_image('uploaded_image.jpg')

file_upload.observe(on_file_upload, names='_counter')

display(file_upload)